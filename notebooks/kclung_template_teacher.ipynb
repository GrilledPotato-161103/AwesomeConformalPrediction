{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeFClDoRZSEt"
      },
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uNOGzJ1ZeUD"
      },
      "source": [
        "## Python Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EtQLou16W1FK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.9.1+cu126\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org\n",
            "Author: \n",
            "Author-email: PyTorch Team <packages@pytorch.org>\n",
            "License: BSD-3-Clause\n",
            "Location: c:\\users\\admin\\.conda\\envs\\conformal\\lib\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: torchvision\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8S2JNQBhZNJq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torchvision\n",
            "Version: 0.24.1+cu126\n",
            "Summary: image and video datasets and models for torch deep learning\n",
            "Home-page: https://github.com/pytorch/vision\n",
            "Author: PyTorch Core Team\n",
            "Author-email: soumith@pytorch.org\n",
            "License: BSD\n",
            "Location: c:\\users\\admin\\.conda\\envs\\conformal\\lib\\site-packages\n",
            "Requires: numpy, pillow, torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G94b2dBak6lp",
        "outputId": "6c0cb5ab-cd94-42db-8626-8631d91c0e5b"
      },
      "outputs": [],
      "source": [
        "# !pip install pydicom onnxruntime-gpu albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6wcVUMnJZPyw"
      },
      "outputs": [],
      "source": [
        "# !pip install matplotlib numpy onnxruntime-gpu pandas tqdm pillow spicy scikit-image==0.21.0 scikit-learn==1.3.2 imantics feret pydicom python-dotenv albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoKoL7PsZk2i"
      },
      "source": [
        "## Drive Mountpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrlzR69iZ9OP"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e:\\AwesomeConformalPrediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\.conda\\envs\\conformal\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XrNRfT30Z-0y"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "import joblib\n",
        "import pydicom\n",
        "import zipfile\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "# import onnxruntime as ort\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import rootutils \n",
        "# rootutils.set_root(os.getcwd(), pythonpath=True)\n",
        "# from src.models.model_2D.segcls.segcls_module import SegClsModule\n",
        "# from src.models.model_2D.segcls.net.segcls import SegClsNet\n",
        "# from src.models.model_2D.segclsnet import segcls\n",
        "# import sys\n",
        "# sys.modules['src.models.model_2D.segcls.net.segcls.SegClsNet'] = SegClsNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kT7nbeMZyjA"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQVXlwY8fg7g"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Ots02FJjHJR"
      },
      "outputs": [],
      "source": [
        "CLS_LUNG_POS_THRESHOLD = [0.35, 0.75, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DLawT3hMZ0lN"
      },
      "outputs": [],
      "source": [
        "dict_columns = {\n",
        "    \"slice_info_columns\": [\"bnid\", \"raw_id\", \"pixel_spacing_w\", \"pixel_spacing_h\", \"intercept\", \"slope\", \"window_center\", \"window_width\"],\n",
        "    \"slice_info_columns_short\": [\"code\", \"slice_id\", \"raw_id\"],\n",
        "    \"nodule\": {\n",
        "        \"dam_do\": [\"Nhóm 1 - Đậm độ - 1.1 Đặc\", \"Nhóm 1 - Đậm độ - 1.2 Bán đặc\", \"Nhóm 1 - Đậm độ - 1.3 Kính mờ\", \"Nhóm 1 - Đậm độ - 1.4 Đông đặc\"],\n",
        "        \"voi_hoa\": [\"Nhóm 2 - Đậm độ vôi - 2.1 Không có vôi\", \"Nhóm 2 - Đậm độ vôi - 2.2 Có vôi\"],\n",
        "        \"chua_mo\": [\"Nhóm 3 - Đậm độ mỡ - 3.1 Không chứa mỡ\", \"Nhóm 3 - Đậm độ mỡ - 3.2 Có chứa mỡ\"],\n",
        "        \"duong_vien\": [\"Nhóm 4 - Bờ và Đường viền - 4.1 Tròn đều\", \"Nhóm 4 - Bờ và Đường viền - 4.2 Đa thuỳ\", \"Nhóm 4 - Bờ và Đường viền - 4.3 Bờ không đều\", \"Nhóm 4 - Bờ và Đường viền - 4.4 Tua gai\"],\n",
        "        \"tao_hang\": [\"Nhóm 5 - Tạo hang - 5.1 Không có\", \"Nhóm 5 - Tạo hang - 5.2 Hang lành tính\", \"Nhóm 5 - Tạo hang - 5.3 Hang ác tính\"],\n",
        "        \"di_can\": [\"Nhóm 6 - Di căn phổi - 6.1 Di căn cùng bên\", \"Nhóm 6 - Di căn phổi - 6.0 Không di căn\", \"Nhóm 6 - Di căn phổi - 6.2 Di căn đối bên\"],\n",
        "    },\n",
        "    \"cls_nodule_group\": {\n",
        "        \"Nhóm 1 - Đậm độ\": ['1.1 Đặc', '1.2 Bán đặc', '1.3 Kính mờ', '1.4 Đông đặc'],\n",
        "        \"Nhóm 2 - Đậm độ vôi\": ['2.1 Không có vôi', '2.2 Có vôi'],\n",
        "        \"Nhóm 3 - Đậm độ mỡ\": ['3.1 Không chứa mỡ', '3.2 Có chứa mỡ'],\n",
        "        \"Nhóm 4 - Bờ và Đường viền\": ['4.1 Tròn đều', '4.2 Đa thuỳ', '4.3 Bờ không đều', '4.4 Tua gai'],\n",
        "        \"Nhóm 5 - Tạo hang\": ['5.1 Không có', '5.2 Hang lành tính', '5.3 Hang ác tính'],\n",
        "        \"Nhóm 6 - Di căn phổi\": ['6.1 Di căn cùng bên', '6.0 Không di căn', '6.2 Di căn đối bên']\n",
        "    },\n",
        "    \"bbox\": [\"left\", \"top\", \"width\", \"height\"],\n",
        "    \"lung_pos\": [\"right_lung\", \"left_lung\"],\n",
        "    \"lung_loc\": [\"Vị trí giải phẫu - 1. Thuỳ trên phải\", \"Vị trí giải phẫu - 2. Thuỳ giữa phải\", \"Vị trí giải phẫu - 3. Thuỳ dưới phải\", \"Vị trí giải phẫu - 4. Thuỳ trên trái\", \"Vị trí giải phẫu - 5. Thuỳ dưới trái\"],\n",
        "    \"lung_damage\": {\n",
        "        \"dong_dac\": [\"not_dong_dac\", \"Tổn thương viêm - 1. Đông đặc\"],\n",
        "        \"kinh_mo\": [\"not_kinh_mo\", \"Tổn thương viêm - 2. Kính mờ\"],\n",
        "        \"phe_quan_do\": [\"not_phe_quan_do\", \"Tổn thương viêm - 3. Hình phế quản đồ\"],\n",
        "        \"nu_tren_canh\": [\"not_nu_tren_canh\", \"Tổn thương viêm - 4. Nốt mờ dạng nụ trên cành\"],\n",
        "    },\n",
        "    \"cls_lung_damage_group\": {\n",
        "        \"Tổn thương viêm - 1. Đông đặc\": [\"not_dong_dac\", \"Tổn thương viêm - 1. Đông đặc\"],\n",
        "        \"Tổn thương viêm - 2. Kính mờ\": [\"not_kinh_mo\", \"Tổn thương viêm - 2. Kính mờ\"],\n",
        "        \"Tổn thương viêm - 3. Hình phế quản đồ\": [\"not_phe_quan_do\", \"Tổn thương viêm - 3. Hình phế quản đồ\"],\n",
        "        \"Tổn thương viêm - 4. Nốt mờ dạng nụ trên cành\": [\"not_nu_tren_canh\", \"Tổn thương viêm - 4. Nốt mờ dạng nụ trên cành\"],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CxwTJmI-aSMN"
      },
      "outputs": [],
      "source": [
        "# Helper\n",
        "def find_bbox(mask: np.array, ratio: bool = False, ssize = [1, 1]):\n",
        "    \"\"\"_summary_\n",
        "    Args:\n",
        "        mask (np.ndarray): (h, w) - np.uint8\n",
        "    Returns:\n",
        "        List[Tuple[int, int, int, int]]: List of bounding boxes\n",
        "    \"\"\"\n",
        "    W, H = ssize\n",
        "    mask = (mask > 0.5).astype(np.uint8)\n",
        "    contours, _ = cv2.findContours(\n",
        "        mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt_bboxes = []\n",
        "    for contour in contours: \n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        if ratio:\n",
        "            cnt_bboxes.append((x / W, y / H, w / W, h / H))\n",
        "        else:\n",
        "            cnt_bboxes.append((x, y, w, h))\n",
        "    return contours, cnt_bboxes\n",
        "\n",
        "def get_bbox(mask: np.ndarray, min_area: int):\n",
        "    def check_tiny_nodule(bbox: Tuple[int, int, int, int], min_area: int = 25) -> bool:\n",
        "        \"\"\"_summary_\n",
        "        Args:\n",
        "            bbox (Tuple[int, int, int, int]): (x, y, w, h)\n",
        "            min_area (int, optional): Defaults to 25.\n",
        "        Returns:\n",
        "            bool: True if bbox area < min_area\n",
        "        \"\"\"\n",
        "        return bbox[2] * bbox[3] < min_area\n",
        "\n",
        "    _, bboxes = find_bbox(mask[0])\n",
        "    filtered_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "        # filter tiny nodule: min_area=25 for image (512x512)\n",
        "        if check_tiny_nodule(bbox, min_area):\n",
        "            x, y, w, h = bbox\n",
        "            mask[0, y: y+h, x: x+w] = 0\n",
        "        else:\n",
        "            filtered_bboxes.append(bbox)\n",
        "\n",
        "    return mask, filtered_bboxes\n",
        "\n",
        "def lung_loc_postprocess(lung_loc_mask):\n",
        "    for i in range(lung_loc_mask.shape[-1]):\n",
        "        mask = lung_loc_mask[:, :, i]\n",
        "        contours, _ = find_bbox(mask)\n",
        "        if len(contours):\n",
        "            max_contour = max(contours, key=cv2.contourArea)\n",
        "            mask = np.zeros_like(mask)\n",
        "            cv2.drawContours(mask, [max_contour], -1,\n",
        "                             (255), thickness=cv2.FILLED)\n",
        "            lung_loc_mask[:, :, i] = (\n",
        "                np.array(mask) / 255.0).astype(lung_loc_mask.dtype)\n",
        "\n",
        "    return lung_loc_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "emOAlwInaUTn"
      },
      "outputs": [],
      "source": [
        "# class KCCTPipeline(nn.Module):\n",
        "#   def __init__(self,\n",
        "#               net: nn.Module,\n",
        "#               output_dir: str,\n",
        "#               device: str,\n",
        "#               use_fp16: bool = True,\n",
        "#               debug: bool = False) -> None:\n",
        "\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.debug = debug\n",
        "#     self.device = device\n",
        "#     self.net: SegClsNet = net\n",
        "#     self.net.to(device)\n",
        "#     self.seg_net = self.net.seg_net\n",
        "#     self.cls_net = self.net.cls_nodule_net\n",
        "#     print(\"\", \"-> Infer Nodule Model loaded!\")\n",
        "#     self.original_size = (512, 512)\n",
        "#     self.preprocessed_size = (352, 352)\n",
        "#     self.output_dir = output_dir\n",
        "\n",
        "#     self.mask_dir = self.output_dir / \"mask\"\n",
        "#     self.csv_dir = self.output_dir / \"csv\"\n",
        "#     self.logit_dir = self.output_dir / \"logit\"\n",
        "\n",
        "#     self.mask_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     self.csv_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     self.logit_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#     df_columns = deepcopy(dict_columns[\"slice_info_columns_short\"])\n",
        "#     df_columns.extend([\"mask_id\"] + dict_columns[\"lung_pos\"])\n",
        "#     df_columns.extend(dict_columns[\"bbox\"])\n",
        "#     for _, group_cols in dict_columns[\"lung_damage\"].items():\n",
        "#         df_columns.extend(group_cols)\n",
        "#     for group, group_cols in dict_columns[\"nodule\"].items():\n",
        "#         df_columns.extend(group_cols)\n",
        "#     self.df_columns = df_columns\n",
        "#     self.init_transform()\n",
        "\n",
        "#     # Initialized\n",
        "#     print()\n",
        "\n",
        "#   # Helper & process\n",
        "#   def init_transform(self):\n",
        "#       bbox_params = A.BboxParams(\n",
        "#           format=\"coco\", label_fields=[\"class_labels\"])\n",
        "#       self.transform_img = A.Compose(\n",
        "#           transforms=[A.Resize(*self.preprocessed_size, p=1)])\n",
        "#       self.rev_transform_mask = A.Compose(\n",
        "#           transforms=[A.Resize(*self.original_size, p=1)])\n",
        "#       self.rev_transform_mask_box = A.Compose(transforms=[A.Resize(*self.original_size, p=1)],\n",
        "#                                               bbox_params=bbox_params)\n",
        "\n",
        "#   def save_csv(self, bnid: str, res_slice: List[List]):\n",
        "#       csv_path = self.csv_dir / f\"{bnid}.csv\"\n",
        "#     #   print(len(res_slice[0]), len(self.df_columns))\n",
        "#       if not csv_path.exists():\n",
        "#           # Create a new CSV file with the specified columns and save it\n",
        "#           df = pd.DataFrame(res_slice, columns=self.df_columns)\n",
        "#           df.to_csv(csv_path, index=False)\n",
        "#       else:\n",
        "#           # Append new rows directly to the existing CSV file\n",
        "#           with open(csv_path, 'a', newline='') as f:\n",
        "#               writer = csv.writer(f)\n",
        "#               writer.writerows(res_slice)\n",
        "\n",
        "#   def ct_normalize(self, image: np.ndarray) -> np.ndarray:\n",
        "#       \"\"\"_summary_: normalization\n",
        "#       Args:\n",
        "#           image (np.ndarray): (h, w) or (c, h, w) or (b, c, h, w)\n",
        "#       Returns:\n",
        "#           np.ndarray: (h, w) or (c, h, w) or (b, c, h, w)\n",
        "#       \"\"\"\n",
        "#       if len(image.shape) == 4:\n",
        "#           min_val = image.amin(dim=(1, 2, 3), keepdim=True)\n",
        "#           max_val = image.amax(dim=(1, 2, 3), keepdim=True)\n",
        "#       else:\n",
        "#           min_val = image.min()\n",
        "#           max_val = image.max()\n",
        "\n",
        "#       if (max_val - min_val).item == 0:\n",
        "#           return image\n",
        "\n",
        "#       return (image - min_val) / (max_val - min_val)\n",
        "\n",
        "#   def preprocess(self, raw_images: np.ndarray) -> np.ndarray:\n",
        "#       \"\"\"_summary_: down-sampling\n",
        "#       Args:\n",
        "#           raw_images (np.ndarray): (512, 512)\n",
        "#       Returns:\n",
        "#           np.ndarray: (1, 1, 352, 352)\n",
        "#       \"\"\"\n",
        "\n",
        "#       norm_images = self.ct_normalize(raw_images)\n",
        "#       transformed = self.transform_img(image=norm_images)\n",
        "#       downsampled_images = transformed[\"image\"]\n",
        "#       return torch.tensor(downsampled_images[None, None, ...], device=self.device)\n",
        "\n",
        "#   def seg_postprocess(self, mask: np.ndarray, bboxes: np.ndarray = np.array([])) -> Tuple[np.ndarray, np.ndarray]:\n",
        "#       \"\"\"_summary_\n",
        "#       Args:\n",
        "#           mask (np.ndarray): (1, 1, 352, 352)\n",
        "#           bboxes (np.ndarray): (n, 4)\n",
        "#       Returns:\n",
        "#           Tuple[np.ndarray, np.ndarray]: [(512, 512), (n, 4)]\n",
        "#       \"\"\"\n",
        "#       mask = (mask > 0.5).astype(np.uint8)  # (1, 1, w, h) -> (1, w, h)\n",
        "#       if mask.shape[0] == 1:  # binary mask\n",
        "#           mask = mask[0]\n",
        "#           if len(bboxes):\n",
        "#               bboxes = bboxes.astype(np.float32)\n",
        "#               fake_label = list(range(bboxes.shape[0]))\n",
        "#               transformed = self.rev_transform_mask_box(image=mask,\n",
        "#                                                         bboxes=bboxes, class_labels=fake_label)\n",
        "#               bboxes = transformed[\"bboxes\"].astype(np.int64)\n",
        "#           else:\n",
        "#               transformed = self.rev_transform_mask(image=mask)\n",
        "\n",
        "#           upsampled_mask = transformed[\"image\"]\n",
        "#           return upsampled_mask, bboxes\n",
        "\n",
        "#       elif mask.shape[0] == 6:\n",
        "#           upsampled_mask = [\n",
        "#               cv2.resize(mask[i], self.original_size, interpolation=cv2.INTER_LINEAR) for i in range(mask.shape[0])\n",
        "#           ]\n",
        "#           upsampled_mask = np.stack(upsampled_mask, axis=-1)\n",
        "#           return upsampled_mask\n",
        "\n",
        "#   def cls_postprocess(self, logits: List[np.ndarray]):\n",
        "#       def softmax(logit, axis: int = None):\n",
        "#           if isinstance(logit, torch.Tensor):\n",
        "#             #   print(logit.shape)\n",
        "#               return F.softmax(logit, dim=axis).cpu().numpy()\n",
        "#           exp_logit = np.exp(logit - np.max(logit, axis=axis, keepdims=True))\n",
        "#           return exp_logit / np.sum(exp_logit, axis=axis, keepdims=True)\n",
        "     \n",
        "#       probs = [softmax(logit, axis=1) for logit in logits]\n",
        "#       return probs\n",
        "\n",
        "#   # modified postprocess\n",
        "#   def ort_postprocess(self, ort_outs):\n",
        "#       out_types = ort_outs.keys()\n",
        "#       probs = ort_outs['seg_nodule'] if isinstance(ort_outs['seg_nodule'], torch.Tensor) else torch.from_numpy(ort_outs['seg_nodule'])\n",
        "#       pred_masks = (probs > 0.5).to(torch.uint8)\n",
        "#       ort_outs['seg_nodule'] = pred_masks.numpy()\n",
        "\n",
        "#       if 'seg_lung_loc' in out_types:\n",
        "#           probs = ort_outs['seg_lung_loc'] if isinstance(ort_outs['seg_lung_loc'], torch.Tensor) else torch.from_numpy(ort_outs['seg_lung_loc'])\n",
        "#           pred_masks = torch.argmax(probs, dim=1)\n",
        "#           pred_masks = F.one_hot(pred_masks, num_classes=probs.shape[1]).permute(0, 3, 1, 2)\n",
        "#           ort_outs['seg_nodule'] = pred_masks.numpy()\n",
        "#       return ort_outs\n",
        "\n",
        "#   # Infer 2D\n",
        "#   @torch.no_grad()\n",
        "#   def infer_2D(self, raw_ct_image: np.array, bnid: str, slice_id: str, raw_id: str, pixel_spacing: np.ndarray, intercept, slope, window_center, window_width, label_bboxes=None, pbar: tqdm=None):\n",
        "#       \"\"\"_summary_: infer2D for one slice\n",
        "#       Args:\n",
        "#           raw_ct_image (np.array): (512, 512)\n",
        "#       \"\"\"\n",
        "#       csv_path = self.csv_dir / f\"{bnid}.csv\"\n",
        "#       # bnid_dir = self.raw_image_dir / bnid\n",
        "#       if csv_path.exists():\n",
        "#           df_case = pd.read_csv(csv_path)\n",
        "#         #   print(raw_id, df_case[\"raw_id\"])\n",
        "#           if raw_id in df_case[\"raw_id\"].values:\n",
        "#             if pbar: \n",
        "#                 pbar.write(f\"{bnid}-{raw_id} infered\".ljust(30))\n",
        "#             else:\n",
        "#                 print(f\"{bnid} - {raw_id} is infered\")\n",
        "#             return\n",
        "#       # else:\n",
        "#           # bnid_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#       # np.save(bnid_dir / f\"{raw_id}.npy\", raw_ct_image)\n",
        "\n",
        "#       preprocessed_images = self.preprocess(raw_ct_image.astype(np.float32))\n",
        "#       seg_outputs = self.net.seg_forward(preprocessed_images)\n",
        "\n",
        "#       seg_nodule = seg_outputs['seg_nodule'][0]  # remove batch\n",
        "#       # seg_lung_loc = outputs[1][0] # remove batch\n",
        "#       cls_lung_pos = seg_outputs['cls_lung_pos']  # remove batch\n",
        "#       fm = seg_outputs['fm'][0]  # remove batch\n",
        "#     #   print(fm.shape, fm)\n",
        "\n",
        "#       seg_nodule, nodule_bboxes = get_bbox(seg_nodule.numpy(),\n",
        "#                                             min_area=(25 * (seg_nodule.shape[1] / self.original_size[0]))**2)\n",
        "#       if label_bboxes: \n",
        "#           nodule_bboxes = list(label_bboxes.values())\n",
        "#         #   print(nodule_bboxes)\n",
        "#           label_ids = list(label_bboxes.keys())\n",
        "#       else: \n",
        "#           label_ids = None\n",
        "     \n",
        "#       nodules = []\n",
        "#     #   fm = torch.nan_to_num(fm)\n",
        "#       for (x, y, w, h) in nodule_bboxes:\n",
        "#           if x < 1: \n",
        "#               W, H = fm.shape[1:]\n",
        "#               (x, y, w, h) = (int(x * W), int(y * H), int(w * W), int(h * H))\n",
        "#         #   print(x,y,w,h)\n",
        "#           nodules.append(fm[:, y: y+h, x: x+w].mean(axis=(1, 2)))\n",
        "#     #   print(nodules)\n",
        "#       if len(nodules):\n",
        "#             nodules = torch.stack(nodules, dim=0)\n",
        "#             cls_outputs = None\n",
        "#             for nodule in nodules:\n",
        "#                 # not supported dynamic batch size\n",
        "#                 output = self.cls_net(nodule.reshape(1, 1024))\n",
        "\n",
        "#                 if cls_outputs == None:\n",
        "#                     cls_outputs = output\n",
        "#                 else:\n",
        "#                     # cls_outputs = torch.cat((cls_outputs, output), dim=0)\n",
        "#                     for id in range(len(output)):\n",
        "#                         cls_outputs[id] = torch.cat((cls_outputs[id], output[id]), dim=0)\n",
        "\n",
        "#             cls_nodule = cls_outputs\n",
        "#             cls_nodule_prob = self.cls_postprocess(cls_nodule)\n",
        "#             # print(cls_nodule_prob)\n",
        "\n",
        "#       seg_nodule, nodule_bboxes = self.seg_postprocess(\n",
        "#           seg_nodule, np.array(nodule_bboxes))\n",
        "#       # seg_lung_loc = lung_loc_postprocess(self.seg_postprocess(seg_lung_loc))\n",
        "#       cls_lung_pos_prob = self.cls_postprocess(cls_lung_pos)\n",
        "#     #   print(cls_lung_pos_prob)\n",
        "\n",
        "#       res_slice = [[bnid, slice_id, raw_id]]\n",
        "#       # first dim: batch\n",
        "#       # second dim: 0 for probability of outside, 1 for probability of inside\n",
        "#       lung_pos_res = [val[0, 1] for val in cls_lung_pos_prob]\n",
        "#       res_slice[0].extend(lung_pos_res)\n",
        "#       # outside slice\n",
        "#       if lung_pos_res[0] < CLS_LUNG_POS_THRESHOLD[0] and lung_pos_res[1] < CLS_LUNG_POS_THRESHOLD[0]:\n",
        "#           seg_nodule = np.zeros_like(seg_nodule)  # clean mask\n",
        "#           nodule_bboxes = []\n",
        "#       # outside slice\n",
        "#       # if lung_pos_res[0] < CLS_LUNG_POS_THRESHOLD[1] and lung_pos_res[1] < CLS_LUNG_POS_THRESHOLD[1]:\n",
        "#       #     seg_lung_loc = np.zeros_like(seg_lung_loc) # clean mask\n",
        "\n",
        "#       # nodule classification\n",
        "#       slice_info, res_slice, nodule_id = res_slice[0], [], -1\n",
        "#       for i, bbox in enumerate(nodule_bboxes):\n",
        "#           if label_ids:\n",
        "#               label_id = label_ids[i]\n",
        "#           else:\n",
        "#               label_id = None\n",
        "#           _cls_nodule_prob = [val[i].tolist()[:-1]\n",
        "#                               for val in cls_nodule_prob]\n",
        "#           nodule_id += 1\n",
        "#           nodule_info = [nodule_id if not label_id else label_id] + list(bbox) + sum(_cls_nodule_prob, [])\n",
        "#           res_slice.append(slice_info + nodule_info)  \n",
        "#       # no nodule -> clean slice\n",
        "#       if len(res_slice) == 0:\n",
        "#         #   _cls_nodule_prob = [-1] * 26\n",
        "#         #   bbox = [-1] * len(dict_columns[\"bbox\"])\n",
        "#         #   no_nodule_info = [nodule_id] + bbox + _cls_nodule_prob\n",
        "          \n",
        "#         #   res_slice.append(slice_info + no_nodule_info)\n",
        "\n",
        "#       if \"logit\" in seg_outputs.keys():\n",
        "#           des_logit_dir = self.logit_dir / bnid\n",
        "#           des_logit_dir.mkdir(parents=True, exist_ok=True)\n",
        "#         #   print(seg_outputs['logit'].shape)\n",
        "#           logit = F.sigmoid(seg_outputs['logit'])[0, 0].cpu().numpy()\n",
        "#           img = (logit * 255).astype(np.uint8)\n",
        "#           cv2.imwrite(des_logit_dir / f\"{raw_id}.jpg\", img)\n",
        "#       else:\n",
        "#           pbar.write(\"Logit is missing\") if pbar is not None else print(\"Logit is missing\")\n",
        "\n",
        "#       if seg_outputs['seg_nodule'].sum() > 0:\n",
        "#           # save nodule mask prediction\n",
        "#           seg_nodule = seg_outputs['seg_nodule'][0, 0].cpu().numpy()\n",
        "#           des_path_mask = self.mask_dir / bnid\n",
        "#           des_path_mask.mkdir(parents=True, exist_ok=True)\n",
        "#           pred_nodule_mask = (seg_nodule > 0.5).astype(np.uint8)\n",
        "#           cv2.imwrite(des_path_mask /\n",
        "#                       f\"{raw_id}.jpg\", pred_nodule_mask * 255)\n",
        "#       else:\n",
        "#           if pbar:\n",
        "#             pbar.set_description_str(f\"{bnid}-{raw_id} empty\")\n",
        "#           else:\n",
        "#             pbar.write(f\"{bnid}-{raw_id} empty seg\")\n",
        "#       # save lung location mask prediction\n",
        "#       # des_path_mask = self.new_mask_dir / bnid\n",
        "#       # des_path_mask.mkdir(parents=True, exist_ok=True)\n",
        "#       # for i in range(1, seg_lung_loc.shape[-1]):\n",
        "#       #     pred_lung_loc_mask = (seg_lung_loc[:,:,i] > 0.5).astype(np.uint8)\n",
        "#       #     if pred_lung_loc_mask.sum() > 0:\n",
        "#       #         cv2.imwrite(des_path_mask / f\"{raw_id}_{i}.jpg\", pred_lung_loc_mask * 255)\n",
        "\n",
        "#       # for resume only save when mask is created\n",
        "#       self.save_csv(bnid, res_slice)\n",
        "\n",
        "#   # Cleaning\n",
        "#   def clean(self, bnid: str, is_res: bool = False):\n",
        "#       # csv remove\n",
        "#       try:\n",
        "#         os.remove(self.csv_dir / f\"{bnid}.csv\")\n",
        "#       except FileNotFoundError:\n",
        "#           pass\n",
        "#       clean_paths = [\n",
        "#           self.mask_dir,\n",
        "#       ]\n",
        "#       for clean_path in clean_paths:\n",
        "#           if os.path.exists(clean_path / bnid):\n",
        "#               shutil.rmtree(clean_path / bnid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyy2aqfQfnGA"
      },
      "source": [
        "## Runtime functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cZKKvtyYfH1Z"
      },
      "outputs": [],
      "source": [
        "# Deployment functions\n",
        "def unzip_study(study_zip_path: str, src_path: str):\n",
        "    study_name = os.path.basename(study_zip_path).split(\".zip\")[0]\n",
        "    study_path = os.path.join(src_path, study_name)\n",
        "    if not os.path.exists(study_path):\n",
        "        os.makedirs(study_path)\n",
        "\n",
        "    with zipfile.ZipFile(study_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(study_path)\n",
        "\n",
        "    return study_path\n",
        "\n",
        "def get_dicoms(study_path: str):\n",
        "    '''\n",
        "    Get all dicoms path from study_path, return a full image paths list.\n",
        "    '''\n",
        "\n",
        "    dicom_paths = []\n",
        "    for root, _, files in os.walk(study_path):\n",
        "        for file in files:\n",
        "            dicom_path = os.path.join(root, file)\n",
        "            dicom_paths.append(dicom_path)\n",
        "\n",
        "    return dicom_paths\n",
        "\n",
        "def sorted_dicom(dicom_paths: List[str], is_filter: bool = True):\n",
        "    paths = []\n",
        "    for dicom_path in dicom_paths:\n",
        "        raw_data = pydicom.dcmread(dicom_path, force=True)\n",
        "\n",
        "        valid = True\n",
        "        if is_filter:\n",
        "            try:\n",
        "                wc = min(raw_data.WindowCenter)\n",
        "                ww = max(raw_data.WindowWidth)\n",
        "                valid = -200 >= wc and wc >= -650 and 1000 <= ww and ww <= 1600\n",
        "            except:\n",
        "                valid = False\n",
        "\n",
        "            if not valid:\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            img_data = np.array(raw_data.pixel_array)\n",
        "            if img_data.shape != (512, 512):\n",
        "                valid = False\n",
        "\n",
        "            series_number = raw_data.SeriesNumber\n",
        "            instance_number = raw_data.InstanceNumber\n",
        "        except:\n",
        "            valid = False\n",
        "\n",
        "        if not valid:\n",
        "            continue\n",
        "\n",
        "        paths.append(\n",
        "            (dicom_path, f\"{series_number:02d}_{instance_number:04d}\"))\n",
        "\n",
        "    if is_filter and len(paths) <= 100:\n",
        "        return sorted_dicom(dicom_paths, is_filter=False)\n",
        "\n",
        "    def key(element):\n",
        "        return element[1]\n",
        "\n",
        "    return sorted(paths, key=key)\n",
        "\n",
        "def check_dicom(dicom_path):\n",
        "    '''\n",
        "    Check if dicom_path is ct image dicom without any wrong tag. Return\n",
        "    '''\n",
        "    try:\n",
        "        dcm = pydicom.dcmread(dicom_path)\n",
        "        dcm_tag = str(dcm.dir)\n",
        "\n",
        "        contains = ''\n",
        "        status = True\n",
        "\n",
        "        # Check \"Patient Protocol\" tag\n",
        "        if \"Patient Protocol\" in dcm_tag:\n",
        "            status = False\n",
        "            contains += \"Patient Protocol\"\n",
        "\n",
        "        # Check \"Dose Report\" tag\n",
        "        if \"Dose Report\" in dcm_tag:\n",
        "            status = False\n",
        "            if len(contains) != 0:\n",
        "                contains += \", \"\n",
        "            contains += \"Dose Report\"\n",
        "\n",
        "        # Check \"pdf\" tag\n",
        "        if \"pdf\" in dcm_tag or \"PDF\" in dcm_tag:\n",
        "            status = False\n",
        "            if len(contains) != 0:\n",
        "                contains += \", \"\n",
        "            contains += \"PDF\"\n",
        "\n",
        "        if not status:\n",
        "            return False, \"Contain \" + contains\n",
        "\n",
        "        # Check \"Pixel Array\" length\n",
        "        pixel_array = dcm.pixel_array\n",
        "        if len(pixel_array) != 512:\n",
        "            return False, \"Length of pixel array is not 512\"\n",
        "\n",
        "        # Check \"PixelSpacing\"\n",
        "        pixel_spacing = dcm.get(\"PixelSpacing\", \"-1\")\n",
        "        if pixel_spacing == \"-1\":\n",
        "            return False, \"Don't have pixel spacing\"\n",
        "\n",
        "        # Check \"Modality\" tag\n",
        "        modality = dcm.Modality\n",
        "        if modality != \"CT\":\n",
        "            return False, \"Is not CT Modality\"\n",
        "\n",
        "        return True, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "def read_input(dicom_path: str):\n",
        "    '''\n",
        "    Read raw dicom data from dicom_path, return pixel_array of that dicom, an unique_id and pixel spacing tag.\n",
        "    '''\n",
        "    raw_data = pydicom.dcmread(dicom_path, force=True)\n",
        "\n",
        "    # series_number = raw_data.SeriesNumber\n",
        "    # instance_number = raw_data.InstanceNumber\n",
        "\n",
        "    wc = raw_data.WindowCenter\n",
        "    ww = raw_data.WindowWidth\n",
        "    if isinstance(wc, pydicom.multival.MultiValue):\n",
        "        wc = wc[0]\n",
        "    if isinstance(ww, pydicom.multival.MultiValue):\n",
        "        ww = ww[0]\n",
        "\n",
        "    intercept = raw_data.RescaleIntercept\n",
        "    slope = raw_data.RescaleSlope\n",
        "\n",
        "    pixel_spacing = raw_data.get('PixelSpacing', np.array([1, 1]))\n",
        "    raw_data = np.array(raw_data.pixel_array)\n",
        "\n",
        "    return raw_data, pixel_spacing, intercept, slope, wc, ww"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc807uoXfskf"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_gray(filename, array):\n",
        "    image = array.copy()\n",
        "    image = (image - image.min()) / image.max()\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    return cv2.imwrite(filename, image[..., None])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aVhLKU0mfYHN"
      },
      "outputs": [],
      "source": [
        "# Pipeline running\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "def pipeline_infer(bnid, data_dir: Path, label_dir: Path, cache_dir: Path, force=True, pbar: tqdm =None):\n",
        "    mask_dir = label_dir / 'mask' / bnid\n",
        "    csv_dir = label_dir / 'csv'\n",
        "    input_cache_dir = cache_dir / bnid\n",
        "    if not os.path.isdir(input_cache_dir):\n",
        "        input_cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "    dicom_paths = get_dicoms(data_dir / bnid)\n",
        "    raw_df = pd.read_csv(csv_dir / f\"{bnid}.csv\")\n",
        "    \n",
        "    df = raw_df[raw_df['mask_id'].notna()]\n",
        "    dicom_paths = sorted(dicom_paths)\n",
        "    # print(len(dicom_paths))\n",
        "    for dicom_path in dicom_paths:\n",
        "        # is_ct, _ = check_dicom(dicom_path)\n",
        "        # if not is_ct:\n",
        "        #     continue\n",
        "        dicom_file = dicom_path.split(\"/\")[-1].split(\".\")[0] + \".jpg\"\n",
        "        cache_file = input_cache_dir / dicom_file\n",
        "\n",
        "        slice_idx = int(dicom_path.split('.')[0].split('_')[-1])\n",
        "        slice_node = raw_df[raw_df['slice_id'] == slice_idx]\n",
        "        raw_id = slice_node['raw_id'].tolist()[0]\n",
        "        node_df = df[df['slice_id'] == slice_idx].copy()\n",
        "        bboxes = dict()\n",
        "        if len(node_df) > 0:\n",
        "            for index, node in node_df.iterrows(): \n",
        "\n",
        "                name = f\"slice_{slice_idx:04d}_{node['mask_id']}.jpg\"\n",
        "                # print(name)\n",
        "                label_mask = cv2.imread(mask_dir / name)[..., 0].astype(float) / 255\n",
        "                # print(label_mask.shape, np.unique(label_mask))\n",
        "                _, slice_bbox = find_bbox(label_mask, ratio=True, ssize=label_mask.shape[:2][::-1])\n",
        "                # print\n",
        "                bboxes[name[:-4]] = deepcopy(slice_bbox[0])\n",
        "        # if pbar:\n",
        "        #     pbar.set_description_str(f\"{bnid}-{raw_id}\".ljust(30), refresh=False)\n",
        "        dcom = pydicom.dcmread(dicom_path, force=True)\n",
        "        data = dcom.pixel_array\n",
        "        # print(pixel_spacing, intercept, slope, wc, ww)\n",
        "        pbar.set_description_str(\"Save to cache:\" + str(save_gray(cache_file, data.copy())))\n",
        "        # print(bboxes)\n",
        "        # system.infer_2D(raw_data, bnid, slice_idx, raw_id, pixel_spacing, intercept, slope, wc, ww, \n",
        "        #                 label_bboxes=bboxes if (len(bboxes) > 0) and force else None, pbar=pbar)\n",
        "    # cancer_pred = system.infer_3D(bnid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksVvmTMYfxdG"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwlUYbrMfzSq"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xVqQxqykOac"
      },
      "source": [
        "Run all above cell, then run the next cell to initialize the inference model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.serialization.add_safe_globals({'src.models.model_2D.segcls.net.segcls.SegClsNet': SegClsNet})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# net = torch.load(\"checkpoints/segcls_struct.pth\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# net.load_state_dict(torch.load(\"checkpoints/segcls.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fJYS5WLJf0ni"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "# now = datetime.now()\n",
        "# output_dir = Path(f\"outputs/4.3_model_teacher/{now.year}_{now.month}_{now.day}-{now.hour}_{now.minute}_{now.second}\")\n",
        "# system = KCCTPipeline(net=net,\n",
        "#                       device=\"cuda:0\",\n",
        "#                       output_dir=output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAy4yfFnmtDR"
      },
      "source": [
        "Run next cell to specify the {bnid} data folder and infer all dcm images inside."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_PAkYXX9gucl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Save to cache:False:   0%|           | Save to cache:False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "Unable to decode the pixel data as the dataset's 'file_meta' has no (0002,0010) 'Transfer Syntax UID' element",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(os\u001b[38;5;241m.\u001b[39mlistdir(data_dir), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference\u001b[39m\u001b[38;5;124m\"\u001b[39m, bar_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{l_bar}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{bar}\u001b[39;00m\u001b[38;5;124m| \u001b[39m\u001b[38;5;132;01m{desc}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bnid \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#         # try:\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mpipeline_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbnid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#         # except Exception as e:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#         #     print(f\"Error: {e}\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#         #     system.clean(bnid)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#         #     continue\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[49], line 41\u001b[0m, in \u001b[0;36mpipeline_infer\u001b[1;34m(bnid, data_dir, label_dir, cache_dir, force, pbar)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# if pbar:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#     pbar.set_description_str(f\"{bnid}-{raw_id}\".ljust(30), refresh=False)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m dcom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(dicom_path, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 41\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# print(pixel_spacing, intercept, slope, wc, ww)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave to cache:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(save_gray(cache_file, data\u001b[38;5;241m.\u001b[39mcopy())))\n",
            "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\conformal\\lib\\site-packages\\pydicom\\dataset.py:918\u001b[0m, in \u001b[0;36mDataset.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# Try the base class attribute getter (fix for issue 332)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\conformal\\lib\\site-packages\\pydicom\\dataset.py:2193\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \n\u001b[0;32m   2137\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;124;03m        that iterates through the image frames.\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\conformal\\lib\\site-packages\\pydicom\\dataset.py:1726\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[1;34m(self, handler_name)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pdh\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;66;03m# Use 'pydicom.pixels' backend\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m     opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoding_plugin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m-> 1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m pixel_array(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_id \u001b[38;5;241m=\u001b[39m get_image_pixel_ids(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1729\u001b[0m     \u001b[38;5;66;03m# Use 'pydicom.pixel_data_handlers' backend\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\conformal\\lib\\site-packages\\pydicom\\pixels\\utils.py:1416\u001b[0m, in \u001b[0;36mpixel_array\u001b[1;34m(src, ds_out, specific_tags, index, raw, decoding_plugin, **kwargs)\u001b[0m\n\u001b[0;32m   1414\u001b[0m file_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tsyntax \u001b[38;5;241m:=\u001b[39m file_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransferSyntaxUID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to decode the pixel data as the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_meta\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no (0002,0010) \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer Syntax UID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m element\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1419\u001b[0m     )\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m get_decoder(tsyntax)\n",
            "\u001b[1;31mAttributeError\u001b[0m: Unable to decode the pixel data as the dataset's 'file_meta' has no (0002,0010) 'Transfer Syntax UID' element"
          ]
        }
      ],
      "source": [
        "# bnid = \"CTB-4\"\n",
        "data_dir = Path(r\"E:/AwesomeConformalPrediction/data/data_conformal/export/dicom\")\n",
        "label_dir = Path(r\"E:/AwesomeConformalPrediction/data/data_conformal/export/ground_truth\")\n",
        "cache_dir = Path(r\"E:/AwesomeConformalPrediction/data/data_conformal/export/cache\")\n",
        "# csv_dir = Path(\"\")\n",
        "# pipeline_infer(system, bnid, data_dir, label_dir, force=True)\n",
        "with tqdm(os.listdir(data_dir), desc=\"Inference\", bar_format=\"{l_bar} {bar}| {desc}\") as pbar:\n",
        "    for bnid in pbar:\n",
        "#         # try:\n",
        "        pipeline_infer(bnid, data_dir, label_dir, cache_dir, force=True, pbar=pbar)\n",
        "#         # except Exception as e:\n",
        "#         #     print(f\"Error: {e}\")\n",
        "#         #     system.clean(bnid)\n",
        "#         #     continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9fDkufxjzLc"
      },
      "source": [
        "Result save at \"model_outputs/{bnid}/\":\n",
        "- \"model_outputs/{bnid}/mask\" -> 2D segmentation mask\n",
        "- \"model_outputs/{bnid}/csv\" -> 2D classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# system.clean(bnid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RozptZajl4Ha"
      },
      "source": [
        "Run next cell to clean model outputs."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3uNOGzJ1ZeUD",
        "VoKoL7PsZk2i",
        "TrlzR69iZ9OP",
        "cyy2aqfQfnGA"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conformal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
